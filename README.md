# Real-Time Speech-to-Text Application
## Project: CripIt - Voice to Text with Whisper.cpp

---

## üìã Overview

A PyQt6-based real-time speech-to-text application using whisper.cpp via `pywhispercpp` bindings for maximum speed and offline capability.

**Key Features:**
- Real-time transcription as you speak
- Whisper Large V3 Turbo (809M) as primary model
- Modular architecture supporting multiple models
- Voice Activity Detection (VAD) for efficient processing
- No-drop recording pipeline (disk-backed FIFO spool)
- Copy-to-clipboard functionality
- Cross-platform support (Windows, macOS, Linux)

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         PyQt6 GUI                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  Text Area  ‚îÇ  ‚îÇ   Controls  ‚îÇ  ‚îÇ Status (VAD/Queue)  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  (Output)   ‚îÇ  ‚îÇ(Start/Stop) ‚îÇ  ‚îÇ + Settings dialog   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Audio Capture Thread                    ‚îÇ
‚îÇ             (sounddevice/PyAudio + WebRTC VAD)             ‚îÇ
‚îÇ  - Finalizes speech segments (silence timeout)             ‚îÇ
‚îÇ  - Hard-splits long speech (max segment duration)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               Disk-Backed Recording Spool (FIFO)           ‚îÇ
‚îÇ              output/spool/{queued,processing,failed}       ‚îÇ
‚îÇ  - Each segment becomes a timestamped sequential WAV job   ‚îÇ
‚îÇ  - If disk is low: stop recording (never silently drop)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               Sequential Transcription Pipeline            ‚îÇ
‚îÇ                 (single worker thread, FIFO)               ‚îÇ
‚îÇ  - Deletes job WAV on success                               ‚îÇ
‚îÇ  - Moves to failed/ on error and continues                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 whisper.cpp (pywhispercpp)                 ‚îÇ
‚îÇ    - CPU by default; CUDA supported when built with CUDA   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÅ Project Structure

```
cripit/
‚îú‚îÄ‚îÄ main.py                 # Entry point
‚îú‚îÄ‚îÄ requirements.txt        # Dependencies
‚îú‚îÄ‚îÄ README.md              # This file
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ settings.py        # App configuration
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ audio_capture.py           # Audio capture + VAD, emits finalized recordings
‚îÇ   ‚îú‚îÄ‚îÄ recording_spool.py         # Disk-backed FIFO spool (timestamped WAV jobs)
‚îÇ   ‚îú‚îÄ‚îÄ transcription_pipeline.py  # Sequential transcription worker (FIFO)
‚îÇ   ‚îú‚îÄ‚îÄ transcriber.py             # whisper.cpp wrapper
‚îÇ   ‚îî‚îÄ‚îÄ model_manager.py           # Model loading/switching
‚îú‚îÄ‚îÄ gui/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main_window.py     # Main PyQt window
‚îÇ   ‚îú‚îÄ‚îÄ text_display.py    # Scrolling text area
‚îÇ   ‚îî‚îÄ‚îÄ controls.py        # Buttons, settings
‚îú‚îÄ‚îÄ models/                # GGML model files (gitignored)
‚îÇ   ‚îî‚îÄ‚îÄ README.md         # Model download instructions
‚îî‚îÄ‚îÄ utils/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îî‚îÄ‚îÄ helpers.py         # Audio processing, etc.
```

---

## üîß Core Components

### 1. Audio Capture (`core/audio_capture.py`)
- **PyAudio** for microphone input
- **Silero VAD** (Voice Activity Detection) for speech detection
- Ring buffer for continuous audio (30-second chunks)
- Callback-driven for real-time processing
- Configurable sample rate: 16kHz (Whisper requirement)

### 2. Transcription Engine (`core/transcriber.py`)
- Uses **pywhispercpp** for whisper.cpp bindings
- Supported models:
  - Whisper Large V3 Turbo (809M) - **PRIMARY**
  - Whisper Large V3 (1.55B) - High quality
  - Distil-Whisper (756M) - Speed
  - Tiny/Base/Small (for testing)
- Auto language detection
- Thread-safe transcription
- Real-time callback for partial results

### 3. Model Manager (`core/model_manager.py`)
- Download/manage GGML models
- Auto-download missing models
- Model switching without restart
- Memory management (unload unused models)

### 4. GUI (`gui/main_window.py`)
**Main Window Components:**
- Large text display (scrollable, copyable)
- Start/Stop recording button
- Model selector dropdown
- Language selector (auto-detect or specific)
- Status bar (recording/processing/idle)
- Settings panel (audio device, VAD sensitivity)
- System tray icon (optional)
- Global hotkey support (Ctrl+Shift+R)

---

## ‚ö° Real-Time Pipeline

### Audio Flow
1. Microphone ‚Üí PyAudio
2. VAD detection (silence vs speech)
3. Audio chunks accumulate while speech detected
4. When speech ends (VAD silence) ‚Üí Finalize a recording segment
5. Segment is spooled to disk as a sequential job (WAV + metadata)

### Transcription Flow
1. Pipeline reads the next spooled job (FIFO)
2. Job WAV ‚Üí whisper.cpp
3. Text result generated
4. Results appended to text display
5. Job WAV is deleted on success (or moved to `output/spool/failed/` on error)

### Threading Model
- **Main thread**: PyQt GUI
- **Audio thread**: Continuous capture
- **Pipeline thread**: Sequential transcription worker (FIFO)

---

## üì¶ Dependencies

```txt
PyQt6>=6.4.0
pywhispercpp>=1.2.0
PyAudio>=0.2.13
torch>=2.0.0        # For Silero VAD
numpy>=1.24.0
requests>=2.28.0    # For model downloading
```

---

## üéõÔ∏è Features

### Core Features
- ‚úÖ Real-time speech-to-text
- ‚úÖ Whisper V3 Turbo (fast, accurate)
- ‚úÖ Multi-model support (switchable)
- ‚úÖ Auto language detection
- ‚úÖ Copy-to-clipboard
- ‚úÖ Audio device selection

### Advanced Features
- ‚úÖ Voice Activity Detection (no silence transcription)
- ‚úÖ Adjustable VAD sensitivity
- ‚úÖ Partial result preview
- ‚úÖ Keyboard shortcuts
- ‚úÖ System tray mode

---

## üß† No-Drop Recording Spool

CripIt uses a disk-backed FIFO spool to ensure finalized recordings are not dropped when transcription falls behind.

- Spool root: `output/spool`
- States:
  - `output/spool/queued/` (backlog)
  - `output/spool/processing/` (in-flight)
  - `output/spool/failed/` (kept on error)

Operational rules:
- Jobs are processed strictly in order.
- On success: job WAV+JSON is deleted (no long-term archive).
- On failure: job is moved to `failed/` and the pipeline continues.
- On low disk: CripIt stops recording and shows an error (never silently drops).

If you are changing settings while the app is running:
- Most settings apply immediately.
- Microphone device changes generally require stopping and starting recording.

## üéØ Supported Models

| Model | Params | Speed | WER | Use Case |
|-------|--------|-------|-----|----------|
| **Whisper Large V3 Turbo** | 809M | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | 7.75% | **PRIMARY** - Best balance |
| Whisper Large V3 | 1.55B | ‚≠ê‚≠ê‚≠ê | 7.4% | High quality, multilingual |
| Distil-Whisper | 756M | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ~7.5% | English-only, fastest |
| Whisper Small | 466M | ‚≠ê‚≠ê‚≠ê‚≠ê | ~10% | Testing, low resource |
| Whisper Base | 142M | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ~15% | Testing only |

---

## üìù Notes

### Model Files
Models are stored in `models/` directory as GGML binary files (.bin). These are NOT included in git.

**Download Models:**
```bash
# Using whisper.cpp's download script
./download-ggml-model.sh large-v3-turbo

# Or manually from:
# https://huggingface.co/ggerganov/whisper.cpp
```

### Audio Requirements
- Sample rate: 16kHz (Whisper requirement)
- Format: 16-bit PCM
- Channels: Mono

### Platform-Specific Notes
- **macOS**: May need to grant microphone permissions
- **Linux**: Requires PortAudio development libraries
- **Windows**: Works with default PyAudio wheels

---

## üîÆ Future Enhancements

- [ ] Export transcription to file
- [ ] Speaker diarization (who is speaking)
- [ ] Integration with OpenCode (the original use case!)
- [ ] Cloud sync for transcriptions
- [ ] Mobile app companion

---

## üìÑ License

MIT License - Open source, free to use and modify.

---

**Created:** January 2026  
**Purpose:** Real-time STT for development workflows  
**Engine:** whisper.cpp + PyQt6
